<!-- .slide: class="center" -->

## 13. 长上下文

*碰到特别特别长的文本怎么办？*

----

## 问题：记性不够长

大多数大语言模型一次只能处理几千个字。

- 一封短邮件？轻松搞定
- 一本 300 页的书？塞不进去
- 一整个代码仓库？更别想了

> 怎么才能让 AI 读得了 **超长** 的文本？

----

## ALiBi：越远越淡化

一种直觉想法：让大语言模型 **天然更关注附近的内容** ，离得远的就少关注一些。

- 不搞复杂的位置编码
- 直接按距离加一个 **小小的递减权重**
- 近处的词获得充分关注，远处的词被逐渐弱化
- 额外好处：能处理 **比训练时更长的文本**

> [ALiBi](https://arxiv.org/abs/2108.12409)（2021）— 靠简单的距离衰减，就能处理更长的文本

----

## 长度外推为什么重要

想象你用短文（500 个词）训练了一个大语言模型，然后让它读一本小说（10 万个词）：

- **旧方法** ：大语言模型只有 1-500 号的“座位号”。第 501 个词？没座位了——大语言模型直接懵了！
- **ALiBi 方法** ：不固定座位号，而是让近处的词天然获得更多关注。第 10 万个词跟第 500 个词一样好用。

就像学会了数到 100，然后就能数到 1,000,000 一样——原理不变，继续数就行。

----

## YaRN：把绳子拉长

还记得 RoPE（旋转位置编码）吗？它有个固有的长度上限。

YaRN 想了个巧办法把它 **拉长** ：

- 调整旋转频率来适配更长的上下文
- 在 4,000 个词上训练的大语言模型可以拉伸到能处理 **128,000 个词**
- 不需要从头重新训练

> [YaRN](https://arxiv.org/abs/2309.00071)（2023）— 把 RoPE 的长度极限拉伸

----

## RoPE 拉伸：一个比喻

把 RoPE 想成一把橡皮尺：

- **原来** ：尺子长 4,000 个刻度——处理短文本刚刚好
- **YaRN 拉伸** ：把尺子拉到 128,000 个刻度——刻度间距变大了，但依然能用
- **怎么做** ：调整旋转频率——低频部分（大的模式）容易拉伸，高频部分（细节）需要小心调整

效果：一个在 4K 上下文上训练的大语言模型，只需几个小时的额外训练就能处理 128K 上下文！

----

## RAG vs 长上下文：谁更好用？

等等——如果上下文能做得足够长，还需要 RAG 吗？

研究人员做了正面比较：

- **长上下文** ：把所有资料一股脑塞进去——方便但非常费算力
- **RAG** ：只搜最相关的部分——省算力但可能漏掉有用信息
- **结论** ：各有所长，得看具体任务来选

> [RAG vs Long Context](https://arxiv.org/abs/2407.16833)（2024）— 两种方案的正面对比

----

## 什么时候用 RAG、什么时候用长上下文

| 场景 | 更好的选择 |
|------|-----------|
| 在几百万文档中搜索 | RAG — 上下文装不下这么多 |
| 分析一份很长的报告 | 长上下文 — 整篇塞进去 |
| 从常见问题库回答 | RAG — 快速检索就够了 |
| 总结一场会议记录 | 长上下文 — 需要完整对话 |
| 带历史记忆的聊天机器人 | 两者结合 — RAG 查旧聊天，长上下文看近期对话 |

实践中最好的系统是 **两者结合** ：先用 RAG 找到相关文档，再把它们放进长上下文窗口做分析。

----

## 长上下文真的靠谱吗？

大语言模型号称能处理 10 万以上的 token，但它 **真的全看懂了** 吗？

- **LongBench v2** ：测试大语言模型对长文本各个位置的理解程度
- **MRCR** ：在超长对话里，AI 能不能找到很久之前提过的一条信息？

很多大语言模型在答案藏在文本 **中间** 位置时表现明显下滑！

> [LongBench v2](https://arxiv.org/abs/2412.15204)（2024）| [MRCR](https://arxiv.org/abs/2409.12640)（2024）

----

## 第 13 章总结

| 论文 | 核心思想 |
|------|----------|
| [ALiBi](https://arxiv.org/abs/2108.12409)（2021） | 按距离衰减注意力，实现长度外推 |
| [YaRN](https://arxiv.org/abs/2309.00071)（2023） | 拉伸 RoPE，支持更长上下文 |
| [RAG vs Long Context](https://arxiv.org/abs/2407.16833)（2024） | 两种方案各有优劣 |
| [LongBench v2](https://arxiv.org/abs/2412.15204)（2024） | 检验长上下文真实理解能力 |
| [MRCR](https://arxiv.org/abs/2409.12640)（2024） | 长对话中的多轮信息检索 |

----

## 想深入了解？

- [Extending Context Length (Hugging Face)](https://huggingface.co/blog/long-context) — 大语言模型如何处理越来越长的文本
- [The Practical Guides to Long Context (blog)](https://kipp.ly/transformer-taxonomy/) — 所有长上下文技术的分类梳理
- [Needle in a Haystack Test](https://github.com/gkamradt/LLMTest_NeedleInAHaystack) — 亲自测试你的大语言模型是不是真的读完了全部内容
- [Extrinsic Hallucinations in LLMs (Lilian Weng)](https://lilianweng.github.io/posts/2024-07-07-hallucination/) — 大语言模型幻觉问题全面梳理

----

## 想一想

- 如果大语言模型能处理 100 万个词的上下文，我们还需要 RAG 吗？各有什么利弊？
- 很多大语言模型在答案藏在长文本的中间位置时表现会下降。你觉得为什么开头和结尾比中间更容易被“记住”？
- YaRN 把大语言模型的上下文从 4K 拉伸到 128K。你觉得拉伸有没有极限，还是理论上可以无限拉下去？
- 假如你能把一整本教材塞进大语言模型的上下文里，这会怎样改变你的学习和备考方式？
