<!-- .slide: class="center" -->

## 8. 参数高效微调

*能不能不从头来，直接教 AI 学新本事？*

----

## 难题：给一个巨人换脑子

你想让 AI 变成一个医疗助手，但基础模型只是个“什么都知道一点”的通才，医学知识远远不够。

- 重新训练全部 700 亿参数得花 **几百万**
- 需要几十张昂贵的 GPU
- 一轮训练动辄好几周

> 能不能不动大语言模型大脑、只加点“医学笔记”就好？

----

## LoRA：给大脑贴便利贴

想象你的大脑是一块冻住的巨大冰块，你不需要把整块冰化了重新冻：

- 在大语言模型的每一层旁边挂一个 **小小的可训练模块**
- 只训练这些小模块，原始大语言模型完全不动
- 这些小模块加起来不到原大语言模型 **1%** 的参数量！

就像在课本上贴便利贴，而不是把课本重写一遍。

> [LoRA](https://arxiv.org/abs/2106.09685)（2021）— 如今微调的行业标准

----

## LoRA 内部是怎么运作的

大语言模型每一层都有一张巨大的权重矩阵（想象成一张超大的数字表格）。

LoRA 的绝招：不动这张大表，而是在旁边加两个 **很小的** 矩阵，让它们相乘：

- 原始矩阵：4096 × 4096 = 1600 万个数字（冻结不动）
- LoRA 矩阵：4096 × 8 + 8 × 4096 = 只有 65,536 个数字（可训练）

只占原来的 **0.4%** ！但效果几乎跟全部重新训练一样好。

----

## QLoRA：一张消费级显卡就能微调

LoRA 训练很省，但光是把 650 亿参数的大语言模型装进内存就得用好几张昂贵的显卡。

QLoRA 叠了两个 buff：

- 先把冻结的大语言模型 **量化压缩** 到 4 比特（体积缩小 16 倍！）
- 然后在压缩后的大语言模型上照常用 LoRA 微调
- 一张 **消费级 GPU** 就能搞定 650 亿参数大语言模型的微调

> [QLoRA](https://arxiv.org/abs/2305.14314)（2023）— 4 比特量化 + LoRA = 人人都能微调

----

## QLoRA：真正让 AI 走进千家万户

在 QLoRA 之前，微调一个大模型需要：
- 一组 8 张以上的昂贵 GPU（硬件成本约 10 万美元以上）
- 好几周的配置和调试

有了 QLoRA：
- 一张普通游戏显卡（约 1000 美元）就够了
- 学生、爱好者、小公司突然都能定制自己的大语言模型了

这才是“AI 民主化”的真正含义——把能力交到每个人手里。

----

## DoRA：LoRA 的升级版

研究人员深入分析了微调到底在调什么，发现：

- 权重的变化可以拆成两部分： **方向** （往哪儿调）和 **幅度** （调多少）
- 普通 LoRA 把两者混在一起调
- DoRA 把它们拆开，分别独立调整

结果是：花一样的钱，效果比 LoRA 更好。

> [DoRA](https://arxiv.org/abs/2402.09353)（2024）— 先拆分、再适配

----

## Prefix-Tuning：只训练“开场白”

换个思路：不碰大语言模型本身，只是在输入前面加几个 **可学习的虚拟 token** 。

- 大语言模型本身完全不动
- 只训练这些“开场白”魔法词
- 它们会学着把大语言模型的输出引向你想要的方向

> [Prefix-Tuning](https://arxiv.org/abs/2101.00190)（2021）— 只训练前缀，不动大语言模型

----

## 微调方法大比拼

| 方法 | 训练什么 | 参数占比 | 显存需求 |
|------|---------|---------|---------|
| 全量微调 | 全部参数 | 100% | 巨大 |
| LoRA | 旁路小矩阵 | 约 0.1% | 中等 |
| QLoRA | LoRA + 4 位量化模型 | 约 0.1% | 很小（1 张卡） |
| Prefix-Tuning | 虚拟 token | 约 0.01% | 非常小 |

趋势很清楚：训得 **越少** ，做得 **越多** 。每种方法都在寻找更巧妙的方式来定制一个冻结的大语言模型。

----

## 实用工具和指南

微调方法这么多，该怎么选？

- **PEFT 综述** ：系统梳理各种方法的优劣和适用场景
- **LLaMA-Factory** ：一站式微调工具，支持 LoRA、QLoRA 等主流方法，几次点击就能搞定 100 多种大语言模型的微调

> [PEFT Survey](https://arxiv.org/abs/2303.15647)（2022）| [LLaMA-Factory](https://arxiv.org/abs/2403.13372)（2024）

----

## 第 8 章总结

| 论文 | 核心思想 |
|------|----------|
| [LoRA](https://arxiv.org/abs/2106.09685)（2021） | 小模块挂上去，只占 0.1% 参数 |
| [QLoRA](https://arxiv.org/abs/2305.14314)（2023） | 4 比特压缩 + LoRA = 一张卡搞定 |
| [DoRA](https://arxiv.org/abs/2402.09353)（2024） | 拆分方向和幅度，分别适配 |
| [Prefix-Tuning](https://arxiv.org/abs/2101.00190)（2021） | 用可学习的前缀引导大语言模型 |
| [LLaMA-Factory](https://arxiv.org/abs/2403.13372)（2024） | 一站式微调工具 |

----

## 想深入了解？

- [LoRA Explained (Lightning AI)](https://lightning.ai/pages/community/lora-insights/) — 图解 LoRA 的工作原理
- [QLoRA: Fine-tune LLMs on a single GPU (Tim Dettmers)](https://timdettmers.com/2023/05/23/qlora-finetuning/) — QLoRA 作者亲自讲解
- [Hugging Face PEFT Library](https://huggingface.co/docs/peft) — 几行代码就能上手 LoRA
- [LLaMA-Factory (GitHub)](https://github.com/hiyouga/LLaMA-Factory) — 用简单界面微调 100 多种大语言模型

----

## 想一想

- LoRA 只训练 0.1% 的参数就能接近全量微调的效果。你觉得为什么这么小的改动能带来这么大的变化？
- QLoRA 让一张消费级显卡就能微调 650 亿参数的大语言模型。当定制 AI 的成本降到这么低，会催生哪些新应用？
- 如果你能微调一个大语言模型，让它成为某个领域的专家，你会选什么领域？为什么？
- Prefix-Tuning 通过添加“魔法词”来引导大语言模型。这跟写一条好的提示词有什么相似和不同之处？
