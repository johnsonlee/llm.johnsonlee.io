<!-- .slide: class="center" -->

## 1. Transformer 基础

*计算机是怎么理解语言的？*

----

## 你是怎么理解一句话的？

读到“小猫坐在垫子上”，你一眼就能看出：

- **谁** 在坐？ — 小猫
- 坐在 **哪儿** ？ — 垫子上
- 在干 **什么** ？ — 坐着

你之所以能理解，是因为你 **一眼就看到了所有的字** ，并且自然地把它们的关系联系了起来。

----

## 计算机能做到吗？

早期的做法是 **逐字阅读** ，就像流水线一样：

> “小” → “猫” → “坐” → “在” → “垫” → “子” → “上”

问题是：读到“上”的时候，前面的“小猫”早就忘了！

- 记忆太短，长句子一多就容易出错
- 速度也慢，只能一个字一个字处理，没法并行

----

## 大语言模型眼里的“字”是什么？

大语言模型不像我们这样认字。它有一个专门的”切字工具”叫 **分词器 (tokenizer)** 。

分词器负责把文本切成一个个小片段，每个片段叫做 **token** ：

- “unhappiness” → “un” + “happiness”（2 个 token）
- “我喜欢吃西瓜” → “我” + “喜欢” + “吃” + “西瓜”（4 个 token）

----

## 分词器怎么决定从哪儿切？

- 在大语言模型训练之前，分词器会先扫描 **训练数据** ，统计哪些片段出现得最频繁，建立一份固定的“词表”
- 之后无论用户输入什么，都按这份词表来切
- “happiness” 出现频率很高 → 保留完整
- “unhappiness” 比较少见 → 拆成 “un” + “happiness”，两个分词器已经认识的碎片
- 中文也一样：“喜欢”“西瓜” 经常一起出现，保留为整体；“吃” 本身就是一个字，单独成一个 token

----

<!-- .slide: class="center" -->

## 假如计算机能一眼看到每个字呢？

----

## 注意力机制 (Attention)：全部一起看

**注意力机制** 就是干这个的！

- 每个字都会“扫一眼”其他所有字，看看谁跟自己最相关
- “坐”看到“猫” → 谁在坐？
- “坐”看到“垫子” → 坐在哪儿？
- 所有字 **同时处理** ，不用排队等

> 这个思路来自 [Attention Is All You Need](https://arxiv.org/abs/1706.03762)（2017），正是这篇论文提出了 **Transformer** 架构

----

## 但是，字的顺序怎么办？

“狗咬人”和“人咬狗”字都一样，意思却天差地别！

- 注意力机制既然是同时看所有字，那它怎么知道哪个字在前、哪个在后？
- 解决办法： **位置编码 (Positional Encoding)** — 给每个字编一个“座位号”

> 第 1 个字：“狗”（1 号位）→ 第 2 个字：“咬”（2 号位）→ 第 3 个字：“人”（3 号位）

有了座位号，大语言模型就能同时知道“字的含义”和“字的顺序”。

----

## 学语言的两条路

想象你在学一门外语，有两种学法：

- **做完形填空** — 挖掉一个词让你猜，练的是*理解*能力
- **接龙写故事** — 给你开头，让你写下一句，练的是*生成*能力

研究人员把两条路都试了一遍！

----

## 路线一：完形填空（BERT）

> “小 ___ 坐在垫子上”

让大语言模型学着猜被挖掉的词，它就变得特别擅长 **理解** 文本。

- 强项：回答问题、给文本分类、信息检索
- 弱项：写故事、聊天这类生成任务

> [BERT](https://arxiv.org/abs/1810.04805)（2018）— 同时从左右两个方向理解上下文

----

## 路线二：接龙猜词（GPT）

> “小猫坐在 ___”

让大语言模型学着预测下一个词，它就变得特别擅长 **生成** 文本。

- 强项：写作、对话、内容创作
- 弱项：需要深入理解全文的任务

> [GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)（2018）— 从左到右逐词预测

----

## 能不能两全其美？

把理解和生成结合起来行不行？

> 思路：把 **所有任务** 都统一成“输入一段文字、输出一段文字”

- 翻译：“English: Hello” → “French: Bonjour”
- 摘要：“一篇长文章…” → “一段简短摘要…”
- 问答：“天空是什么颜色？” → “蓝色”

> [T5](https://arxiv.org/abs/1910.10683)（2019）— 一个模型、一种格式，通吃所有任务

----

## 更精巧的设计一定更好吗？

答案出人意料： **不一定** ！

研究人员发现，与其设计更复杂的模型结构，不如把简单模型 **训练得更充分** 、喂 **更多数据** ：

- 多练几轮，别急着停
- 多用新数据，少重复旧数据
- 训练方法比模型设计更关键

> [RoBERTa](https://arxiv.org/abs/1907.11692)（2019）— 同样的 BERT 架构，靠训练技巧取胜

----

## 第 1 章总结

| 论文 | 核心思想 |
|------|----------|
| [Attention Is All You Need](https://arxiv.org/abs/1706.03762)（2017） | 同时看所有字 — Transformer 诞生 |
| [BERT](https://arxiv.org/abs/1810.04805)（2018） | 完形填空 → 擅长理解 |
| [GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)（2018） | 接龙猜词 → 擅长生成 |
| [T5](https://arxiv.org/abs/1910.10683)（2019） | 一切任务 = 文本进、文本出 |
| [RoBERTa](https://arxiv.org/abs/1907.11692)（2019） | 训练方法比模型设计更重要 |
