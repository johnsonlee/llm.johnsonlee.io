<!-- .slide: class="center" -->

## 3. 缩放定律与训练理论

*脑子越大就一定越聪明吗？*

----

## 我们已经看到：大语言模型越大越聪明

GPT-2（15 亿）→ GPT-3（1750 亿），每一次“变大”都带来新能力。

但训练大模型动辄要花 **几百万美元** ，所以必须搞清楚一个问题：

> 预算有限的情况下，是该造一个 **更大的大语言模型** ，还是准备 **更多的数据** ？

----

## 缩放定律 (Scaling Laws)：花钱的科学

研究人员发现了一条出奇简单的规律：

- 大语言模型的表现可以用一个 **简单的数学规律** 来预测
- 参数越多 → 越好（但每多花一块钱，进步就小一点）
- 数据越多 → 越好（但每多花一块钱，进步就小一点）
- 算力越多 → 越好（但每多花一块钱，进步就小一点）

也就是说，你甚至可以在训练之前就 **估算** 出大语言模型的表现！

> [Scaling Laws (Kaplan)](https://arxiv.org/abs/2001.08361)（2020）— AI 性能的预测公式

----

## 生活中的缩放定律

缩放定律就像学乐器：

- **第一周** ：进步飞快——从噪音变成能弹简单曲子
- **第一个月** ：进步明显——能弹完整的歌了
- **第一年** ：进步变慢——在变好，但每多练一小时带来的提升越来越小

大语言模型也是同样的规律。把大语言模型翻一倍不等于性能翻一倍——但进步是 **可预测的** ，这才是真正了不起的地方。

----

## 等等，之前的配方搞错了！

最初的结论是： **预算大头应该花在做大模型上** 。

但 DeepMind 团队发现正好相反：

- 大多数团队给大语言模型喂的数据 **远远不够**
- 一个 700 亿参数的大语言模型配上 4 倍数据，竟然打败了 2800 亿参数但数据少的大语言模型
- 正确做法是让数据和参数 **同步增长**

> [Chinchilla](https://arxiv.org/abs/2203.15556)（2022）— “你们的大语言模型都没喂饱！”

----

## Chinchilla 的“配方”

训练大语言模型就像烤蛋糕：

- **旧配方 (Kaplan)** ：用一个超大烤箱（大模型），但面糊放得少（数据不够）
- **Chinchilla 配方** ：用中号烤箱，配上恰到好处的面糊

核心发现：每花一块钱，大约 **一半给大语言模型大小、一半给数据量** 效果最好。以前大多数团队在大语言模型大小上花了太多钱，在数据上却舍不得投入。

----

## 涌现能力 (Emergent Abilities)：突然开窍

大语言模型变大的过程中会出现很神奇的现象：

- 小模型做不了算术 → 稍大一点还是不行 → 再大一些—— **突然就会了！**
- 就好像突然“开窍”了一样，某些能力凭空冒了出来
- 这类能力被称为 **涌现能力** ，从来没有人专门教过它

> [Emergent Abilities](https://arxiv.org/abs/2206.07682)（2022）— 规模催生出的意外惊喜

----

## 涌现为什么让人惊讶

想象你教一个小朋友做加法：1+1、2+3、5+7……

有一天你突然问：“1,247 + 3,856 等于多少？”——他竟然算对了！但你从来没教过这么大的数。

这就是涌现：大语言模型先学会基础的规律，到了某个临界点，这些规律自发组合出全新的能力——没有人专门教过它。

----

## 真的是突然开窍吗？

也有人提出了不同意见：

- 也许这些能力并不是“突然”出现的
- 换一种 **评估方式** 去看，进步其实是 **循序渐进** 的
- 所谓的“魔法”，也许只是我们衡量方式造成的错觉

> [Are Emergent Abilities a Mirage?](https://arxiv.org/abs/2304.15004)（2023）— 泼一盆冷水也是好事

----

## 数据不够用了怎么办？

互联网虽大，数据量终究有限。当大语言模型的胃口超过了现有的数据量，该怎么办？

- 可以 **重复使用** 数据，但超过约 4 轮之后效果就会下降
- 可以 **混入代码和数学** 等不同类型的数据来帮助学习
- 还可以 **生成合成数据** ——让 AI 给 AI 写训练材料

> [Scaling Data-Constrained Language Models](https://arxiv.org/abs/2305.16264)（2023）— 当数据成了瓶颈

----

## 第 3 章总结

| 论文 | 核心思想 |
|------|----------|
| [Scaling Laws](https://arxiv.org/abs/2001.08361)（2020） | 大语言模型表现有规律可循，花钱之前就能估算 |
| [Chinchilla](https://arxiv.org/abs/2203.15556)（2022） | 数据要跟上——大部分大语言模型都没喂饱 |
| [Emergent Abilities](https://arxiv.org/abs/2206.07682)（2022） | 大语言模型够大之后，新能力突然涌现 |
| [Mirage?](https://arxiv.org/abs/2304.15004)（2023） | 也许是评估方式在搞鬼 |
| [Data-Constrained](https://arxiv.org/abs/2305.16264)（2023） | 数据有限时的应对策略 |

----

## 想深入了解？

- [Chinchilla's Wild Implications (nostalgebraist)](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) — Chinchilla 对 AI 发展路线的深远影响
- [Emergent Abilities Explained (AI Explained)](https://www.youtube.com/watch?v=dDUC-LqVrPU) — 用实例讲解涌现能力（视频）
- [The Scaling Hypothesis (Gwern)](https://gwern.net/scaling-hypothesis) — 深度解析“越大越好”假说
- [Are Emergent Abilities a Mirage? (Yannic Kilcher)](https://www.youtube.com/watch?v=hQQUkbJHJg4) — 讲解涌现能力的争议（视频）

----

## 想一想

- 如果给你 1000 万美元来训练一个大语言模型，你会造更大的大语言模型还是找更多的数据？为什么？
- 涌现能力是“突然”冒出来的。你自己的学习中有没有过类似的经历——练了很久，某天突然就会了？
- 互联网上的文本是有限的。如果需要的训练数据比现有的还多，你会怎么办？
- 如果“涌现是幻觉”那篇论文说得对，涌现只是评估方式的问题，这会让大语言模型变得不那么厉害吗？为什么？
